{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d7cbef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from imutils import contours\n",
    "\n",
    "# Load image, grayscale, Gaussian blur, Canny edge detection\n",
    "image = cv2.imread(\"test_img/newtest3.jpg\")\n",
    "original = image.copy()\n",
    "\n",
    "#Convert to grayscale image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Adaptive thresholding\n",
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 4)\n",
    "# Histogram equalization\n",
    "equalized = cv2.equalizeHist(thresh)\n",
    "# Apply Gaussian blur \n",
    "blurred = cv2.GaussianBlur(equalized, (3,3), 0)\n",
    "# Apply canny edge detection\n",
    "canny = cv2.Canny(blurred, 120, 255, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Find contours and extract ROI\n",
    "# ROI_number = 0\n",
    "# cnts = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "# cnts, _ = contours.sort_contours(cnts, method=\"left-to-right\")\n",
    "# for c in cnts:\n",
    "#     x,y,w,h = cv2.boundingRect(c)\n",
    "#     ROI = original[y:y+h, x:x+w]\n",
    "#     cv2.rectangle(image, (x,y), (x+w,y+h),(36, 255, 12), 3)\n",
    "# #     cv2.imwrite('ROI_{}.png'.format(ROI_number), ROI)\n",
    "#     ROI_number += 1\n",
    "\n",
    "# print('Contours Detected: {}'.format(ROI_number))\n",
    "\n",
    "#Display original image\n",
    "cv2.imshow(\"image\", image) \n",
    "# Display grayscale image\n",
    "cv2.imshow(\"Grayscale Image\", gray)\n",
    "#Display thresholded image\n",
    "cv2.imshow(\"Thresholding image\", thresh) \n",
    "# Display equalized image\n",
    "cv2.imshow(\"Equalized Image\", equalized)\n",
    "# Display blurred image\n",
    "cv2.imshow(\"Blurred Image\", blurred)\n",
    "cv2.imshow(\"canny\", canny)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1696a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Improved Canny Algorithm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_gradients(image):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate gradients using 3x3 neighboring area\n",
    "    Gx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    Gy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    # Compute gradient magnitude and direction\n",
    "    magnitude = np.sqrt(Gx**2 + Gy**2)\n",
    "    direction = np.arctan2(Gy, Gx) * (180 / np.pi)\n",
    "    \n",
    "    return magnitude, direction\n",
    "\n",
    "def adaptive_threshold_selection(image, magnitude, mean_percentage=0.15, neighborhood_size=21):\n",
    "    # Calculate mean gradient magnitude\n",
    "    mean_magnitude = np.mean(magnitude)\n",
    "    \n",
    "    # Initialize output edge map\n",
    "    edges = np.zeros_like(magnitude)\n",
    "    \n",
    "    # Iterate over image pixels\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            # Calculate local neighborhood\n",
    "            start_row = max(0, i - neighborhood_size // 2)\n",
    "            end_row = min(image.shape[0], i + neighborhood_size // 2 + 1)\n",
    "            start_col = max(0, j - neighborhood_size // 2)\n",
    "            end_col = min(image.shape[1], j + neighborhood_size // 2 + 1)\n",
    "            local_magnitude = magnitude[start_row:end_row, start_col:end_col]\n",
    "            \n",
    "            # Calculate threshold based on local mean and standard deviation\n",
    "            local_mean = np.mean(local_magnitude)\n",
    "            local_std = np.std(local_magnitude)\n",
    "            threshold = local_mean + local_std\n",
    "            \n",
    "            # Apply adaptive thresholding\n",
    "            if magnitude[i, j] >= threshold:\n",
    "                edges[i, j] = 255\n",
    "    \n",
    "    return edges\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('test_img/newtest3.jpg')\n",
    "\n",
    "# Calculate gradients\n",
    "magnitude, direction = calculate_gradients(image)\n",
    "\n",
    "# Adaptive threshold selection\n",
    "edges = adaptive_threshold_selection(image, magnitude)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('test_img/newtest2.jpg', image)\n",
    "cv2.imshow('Edge Map', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19be43cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Traditional Canny Algorithm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def CannyEdgeDetection(image, low_threshold, high_threshold):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to the image\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    \n",
    "    # Compute gradients using Sobel operator\n",
    "    sobel_x = cv2.Sobel(blurred_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(blurred_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    # Compute gradient magnitude and direction\n",
    "    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    gradient_direction = np.arctan2(sobel_y, sobel_x) * (180 / np.pi)\n",
    "    \n",
    "    # Round gradient direction to four main directions: 0, 45, 90, 135 degrees\n",
    "    rounded_direction = np.zeros_like(gradient_direction)\n",
    "    rounded_direction[np.where((gradient_direction >= -22.5) & (gradient_direction < 22.5))] = 0\n",
    "    rounded_direction[np.where((gradient_direction >= 22.5) & (gradient_direction < 67.5))] = 45\n",
    "    rounded_direction[np.where((gradient_direction >= -67.5) & (gradient_direction < -22.5))] = 135\n",
    "    rounded_direction[np.where((gradient_direction >= 67.5) | (gradient_direction < -67.5))] = 90\n",
    "    \n",
    "    # Apply non-maximum suppression\n",
    "    suppressed_magnitude = np.zeros_like(gradient_magnitude)\n",
    "    for i in range(1, gradient_magnitude.shape[0]-1):\n",
    "        for j in range(1, gradient_magnitude.shape[1]-1):\n",
    "            direction = rounded_direction[i, j]\n",
    "            if direction == 0:\n",
    "                neighbors = [gradient_magnitude[i, j-1], gradient_magnitude[i, j+1]]\n",
    "            elif direction == 45:\n",
    "                neighbors = [gradient_magnitude[i-1, j-1], gradient_magnitude[i+1, j+1]]\n",
    "            elif direction == 90:\n",
    "                neighbors = [gradient_magnitude[i-1, j], gradient_magnitude[i+1, j]]\n",
    "            elif direction == 135:\n",
    "                neighbors = [gradient_magnitude[i-1, j+1], gradient_magnitude[i+1, j-1]]\n",
    "            if gradient_magnitude[i, j] >= max(neighbors):\n",
    "                suppressed_magnitude[i, j] = gradient_magnitude[i, j]\n",
    "    \n",
    "    # Apply double thresholding\n",
    "    high_threshold = np.max(suppressed_magnitude) * high_threshold\n",
    "    low_threshold = high_threshold * low_threshold\n",
    "    edges = np.zeros_like(suppressed_magnitude)\n",
    "    strong_i, strong_j = np.where(suppressed_magnitude >= high_threshold)\n",
    "    weak_i, weak_j = np.where((suppressed_magnitude >= low_threshold) & (suppressed_magnitude < high_threshold))\n",
    "    \n",
    "    edges[strong_i, strong_j] = 255\n",
    "    edges[weak_i, weak_j] = 50\n",
    "    \n",
    "    # Apply edge tracking by hysteresis\n",
    "    for i in range(1, edges.shape[0]-1):\n",
    "        for j in range(1, edges.shape[1]-1):\n",
    "            if edges[i, j] == 50:\n",
    "                if np.max(edges[i-1:i+2, j-1:j+2]) == 255:\n",
    "                    edges[i, j] = 255\n",
    "                else:\n",
    "                    edges[i, j] = 0\n",
    "    \n",
    "    return edges\n",
    "\n",
    "# Example usage:\n",
    "image = cv2.imread('test_img/newtest3.jpg')\n",
    "# edges = CannyEdgeDetection(image, 0.05, 0.15)\n",
    "edges = CannyEdgeDetection(image, 0.25, 0.3)\n",
    "# print(image.shape,edges.shape)\n",
    "cv2.imwrite('canny_edges.jpg', edges)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4057fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: Game 2048 Digit Recognition -*-\n",
    "\n",
    "################################################### Best Performance ###########################################\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('test_img/newtest4.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "############################### Histogram equalization ####################################\n",
    "equalized = cv2.equalizeHist(gray)\n",
    "\n",
    "cv2.imshow('equalized image',equalized )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "############################### Binary Thresholding ########################################\n",
    "ret,thresh = cv2.threshold(equalized,190,255,1)\n",
    "\n",
    "\n",
    "cv2.imshow('thresh',thresh )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "############################# Method 1 (Unused)##################################################### \n",
    "# # 对二值图像执行膨胀操作\n",
    "# # kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(2, 2))\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "# # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "# dilated = cv2.dilate(thresh,kernel)\n",
    "\n",
    "# cv2.imshow('dilated',dilated )\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "############################## Method 2 ####################################################\n",
    "## Perform iterative morphological operations (Opening operation)\n",
    "# Define the kernel for morphological operations\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))  # Adjust kernel size as needed\n",
    "\n",
    "# Perform opening operation (dilation followed by erosion) iteratively\n",
    "num_iterations = 2  # Number of iterations\n",
    "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=num_iterations)\n",
    "\n",
    "# Display the result of opening operation\n",
    "cv2.imshow('Opened Image', opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite('temp/opening.jpg', opening)\n",
    "\n",
    "################################ Extract inside image (Unused) #########################################\n",
    "\n",
    "# # Find contours in the binary image\n",
    "# contours, _ = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Find the outermost contour (largest contour area)\n",
    "# outer_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# # Create a mask for the outer contour\n",
    "# mask = np.zeros_like(opening)\n",
    "# cv2.drawContours(mask, [outer_contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "# # Apply the mask to the original image to extract the region inside the contour\n",
    "# image_inside_contour = cv2.bitwise_and(opening, opening, mask=mask)\n",
    "\n",
    "# # Save or display the extracted region\n",
    "# cv2.imwrite('image_inside_contour.jpg', image_inside_contour)\n",
    "# # cv2.imshow('Image Inside Contour', image_inside_contour)\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "############################## Divide into 16 Blocks ###########################################\n",
    "\n",
    "# Get the dimensions of the original image\n",
    "height, width = opening.shape\n",
    "\n",
    "# Calculate the dimensions of each small image\n",
    "small_image_height = height // 4\n",
    "small_image_width = width // 4\n",
    "\n",
    "# Initialize a list to store the small images\n",
    "small_images = []\n",
    "\n",
    "# Iterate over the rows of the grid\n",
    "for i in range(4):\n",
    "    # Calculate the y-coordinate range for the current row\n",
    "    y_start = i * small_image_height\n",
    "    y_end = (i + 1) * small_image_height\n",
    "    \n",
    "    # Iterate over the columns of the grid\n",
    "    for j in range(4):\n",
    "        # Calculate the x-coordinate range for the current column\n",
    "        x_start = j * small_image_width\n",
    "        x_end = (j + 1) * small_image_width\n",
    "        \n",
    "        # Extract the small image from the original image\n",
    "        small_image = opening[y_start:y_end, x_start:x_end]\n",
    "        \n",
    "        # Add the small image to the list\n",
    "        small_images.append(small_image)\n",
    "\n",
    "# Display or save the small images\n",
    "for idx, small_image in enumerate(small_images):\n",
    "    cv2.imwrite(f'temp/small_image_{idx}.jpg', small_image)\n",
    "    # Uncomment the following line to display the small images\n",
    "    # cv2.imshow(f'Small Image {idx}', small_image)\n",
    "\n",
    "# Uncomment the following line to display the small images\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "#################### Invert the Binary Image #########################################\n",
    "# # Invert the colors of each small image\n",
    "# inverted_images = [255 - image for image in small_images]\n",
    "\n",
    "# # Display or save the inverted images\n",
    "# for idx, inverted_image in enumerate(inverted_images):\n",
    "#     cv2.imwrite(f'inverted_image_{idx}.jpg', inverted_image)\n",
    "#     # Uncomment the following line to display the inverted images\n",
    "#     # cv2.imshow(f'Inverted Image {idx}', inverted_image)\n",
    "\n",
    "# # Uncomment the following line to display the inverted images\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()\n",
    "\n",
    "####################### Resize to the Standard 187 * 186 Image #################################################\n",
    "# Define the desired dimensions for resizing\n",
    "new_width = 187\n",
    "new_height = 186\n",
    "\n",
    "\n",
    "# Resize each small image\n",
    "resized_images = [cv2.resize(image, (new_width, new_height)) for image in small_images]\n",
    "\n",
    "## Perform iterative morphological operations for each resized image\n",
    "\n",
    "# Define the kernel for morphological operations\n",
    "kernel_1 = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))  # Adjust kernel size as needed\n",
    "# Perform opening operation (dilation followed by erosion) iteratively\n",
    "num_iterations = 2  # Number of iterations\n",
    "    \n",
    "for img in resized_images:\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel_1, iterations=num_iterations)\n",
    "\n",
    "# Display or save the resized images\n",
    "for idx, resized_image in enumerate(resized_images):\n",
    "    cv2.imwrite(f'input_img/resized_image_{idx}.jpg', resized_image)\n",
    "    # Uncomment the following line to display the resized images\n",
    "    # cv2.imshow(f'Resized Image {idx}', resized_image)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d8080a2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "No digit recognized for resized_image_0.jpg\n",
      "1\n",
      "0.53949696\n",
      "Recognized Digit for resized_image_1.jpg: 2\n",
      "10\n",
      "0.34915483\n",
      "Recognized Digit for resized_image_10.jpg: 128\n",
      "11\n",
      "0.36490333\n",
      "Recognized Digit for resized_image_11.jpg: 4\n",
      "0.0\n",
      "No digit recognized for resized_image_12.jpg\n",
      "0.062492035\n",
      "No digit recognized for resized_image_13.jpg\n",
      "14\n",
      "0.4537652\n",
      "Recognized Digit for resized_image_14.jpg: 2\n",
      "0.24829598\n",
      "No digit recognized for resized_image_15.jpg\n",
      "2\n",
      "0.5611999\n",
      "Recognized Digit for resized_image_2.jpg: 16\n",
      "0.18146123\n",
      "No digit recognized for resized_image_3.jpg\n",
      "4\n",
      "0.38060892\n",
      "Recognized Digit for resized_image_4.jpg: 2\n",
      "5\n",
      "0.37042758\n",
      "Recognized Digit for resized_image_5.jpg: 16\n",
      "6\n",
      "0.5880812\n",
      "Recognized Digit for resized_image_6.jpg: 16\n",
      "7\n",
      "0.38267523\n",
      "Recognized Digit for resized_image_7.jpg: 4\n",
      "0.14240648\n",
      "No digit recognized for resized_image_8.jpg\n",
      "9\n",
      "0.647941\n",
      "Recognized Digit for resized_image_9.jpg: 2\n",
      "[['' '2' '16' '']\n",
      " ['2' '16' '16' '4']\n",
      " ['' '2' '128' '4']\n",
      " ['' '' '2' '']]\n"
     ]
    }
   ],
   "source": [
    "############################## Digit Recognition #################################\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Define the folder containing input images\n",
    "input_folder = 'input_img/'\n",
    "\n",
    "# Define the folder containing the standard labeled digit images\n",
    "standard_digit_folder = 'label_img/'\n",
    "\n",
    "# Define the threshold for the correlation score\n",
    "correlation_threshold = 0.3  # Adjust as neede\n",
    "\n",
    "# Initialize a 4x4 matrix to store recognized digits\n",
    "recognized_matrix = [['' for _ in range(4)] for _ in range(4)]\n",
    "\n",
    "# Iterate through each input image\n",
    "for input_filename in os.listdir(input_folder):\n",
    "    # Load the input image containing a digit\n",
    "    input_image = cv2.imread(os.path.join(input_folder, input_filename), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Initialize variables to store the maximum correlation score and recognized digit\n",
    "    max_correlation_score = -1\n",
    "    recognized_digit = None\n",
    "    \n",
    "    # Iterate through each standard digit image\n",
    "    for digit_filename in os.listdir(standard_digit_folder):\n",
    "        # Load the standard digit image\n",
    "        standard_digit_image = cv2.imread(os.path.join(standard_digit_folder, digit_filename), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Calculate the correlation score between the input image and the standard digit image\n",
    "        correlation_score = cv2.matchTemplate(input_image, standard_digit_image, cv2.TM_CCOEFF_NORMED)[0][0]\n",
    "        \n",
    "        # Update the recognized digit if the correlation score is higher\n",
    "        if correlation_score > max_correlation_score:\n",
    "            max_correlation_score = correlation_score\n",
    "            recognized_digit = digit_filename.split(\".\")[0].split(\"_\")[-1]  # Extract the digit from the filename\n",
    "    \n",
    "    # Check if the correlation score exceeds the threshold\n",
    "    if max_correlation_score >= correlation_threshold:\n",
    "        # Output the recognized digit for the current input image\n",
    "        \n",
    "        # Extract the row and column indices from the input filename\n",
    "        \n",
    "        index = int(input_filename.split('.')[0].split('_')[-1])\n",
    "        print(index)\n",
    "        row,col= index//4,index % 4\n",
    "        \n",
    "        # Update the recognized matrix with the recognized digit\n",
    "        recognized_matrix[row][col] = int(recognized_digit)\n",
    "        \n",
    "        print(max_correlation_score)\n",
    "        print(f\"Recognized Digit for {input_filename}: {recognized_digit}\")\n",
    "    else:\n",
    "        # Output that the input image does not contain any digit\n",
    "        print(max_correlation_score)\n",
    "        print(f\"No digit recognized for {input_filename}\")\n",
    "##########################  Output Matrix ####################################\n",
    "print(np.array(recognized_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c359410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### Build the Standard Library #########################################\n",
    "img = cv2.imread('label_img/black_2048.jpg')\n",
    "# Invert the colors of each small image\n",
    "inverted_image = 255 - img\n",
    "cv2.imwrite(\"label_img/new_white_2048.jpg\", inverted_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "886f0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################   Revised version #################################\n",
    "######## We divide the original image into 16 blocks first and then  perform the following operations #########\n",
    "\n",
    "# -*- coding: Game 2048 Digit Recognition -*-\n",
    "\n",
    "################################################### Best Performance ###########################################\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('test_img/newtest4.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "############################## Divide into 16 Blocks ###########################################\n",
    "\n",
    "# Get the dimensions of the original image\n",
    "height, width = gray.shape\n",
    "\n",
    "# Calculate the dimensions of each small image\n",
    "small_image_height = height // 4\n",
    "small_image_width = width // 4\n",
    "\n",
    "# Initialize a list to store the small images\n",
    "small_images = []\n",
    "\n",
    "# Iterate over the rows of the grid\n",
    "for i in range(4):\n",
    "    # Calculate the y-coordinate range for the current row\n",
    "    y_start = i * small_image_height\n",
    "    y_end = (i + 1) * small_image_height\n",
    "    \n",
    "    # Iterate over the columns of the grid\n",
    "    for j in range(4):\n",
    "        # Calculate the x-coordinate range for the current column\n",
    "        x_start = j * small_image_width\n",
    "        x_end = (j + 1) * small_image_width\n",
    "        \n",
    "        # Extract the small image from the original image\n",
    "        small_image = opening[y_start:y_end, x_start:x_end]\n",
    "        \n",
    "        # Add the small image to the list\n",
    "        small_images.append(small_image)\n",
    "\n",
    "# Display or save the small images\n",
    "for idx, small_image in enumerate(small_images):\n",
    "    cv2.imwrite(f'temp/small_image_{idx}.jpg', small_image)\n",
    "    # Uncomment the following line to display the small images\n",
    "    # cv2.imshow(f'Small Image {idx}', small_image)\n",
    "\n",
    "# Uncomment the following line to display the small images\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "####################### Resize to the Standard 187 * 186 Image #################################################\n",
    "# Define the desired dimensions for resizing\n",
    "new_width = 187\n",
    "new_height = 186\n",
    "\n",
    "\n",
    "# Resize each small image\n",
    "for img in small_images:\n",
    "    img = cv2.resize(img, (new_width, new_height))\n",
    "\n",
    "############################### Histogram equalization ####################################\n",
    "for img in small_images:\n",
    "    img = cv2.equalizeHist(img)\n",
    "    \n",
    "\n",
    "# cv2.imshow('equalized image',equalized )\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "############################### Binary Thresholding ########################################\n",
    "for img in small_images:\n",
    "    ret,thresh = cv2.threshold(equalized,190,255,1)\n",
    "    img = ret\n",
    "\n",
    "# cv2.imshow('thresh',thresh )\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "############################# Method 1 ##################################################### \n",
    "# # 对二值图像执行膨胀操作\n",
    "# # kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(2, 2))\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "# # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "# dilated = cv2.dilate(thresh,kernel)\n",
    "\n",
    "# cv2.imshow('dilated',dilated )\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "############################## Method 2 ####################################################\n",
    "## Perform iterative morphological operations (Opening operation)\n",
    "# Define the kernel for morphological operations\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))  # Adjust kernel size as needed\n",
    "\n",
    "# Perform opening operation (dilation followed by erosion) iteratively\n",
    "num_iterations = 2  # Number of iterations\n",
    "for img in small_images:\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations=num_iterations)\n",
    "\n",
    "# Display the result of opening operation\n",
    "# cv2.imshow('Opened Image', opening)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# cv2.imwrite('temp/opening.jpg', opening)\n",
    "\n",
    "################################ Extract inside image #########################################\n",
    "\n",
    "# # Find contours in the binary image\n",
    "# contours, _ = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Find the outermost contour (largest contour area)\n",
    "# outer_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# # Create a mask for the outer contour\n",
    "# mask = np.zeros_like(opening)\n",
    "# cv2.drawContours(mask, [outer_contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "# # Apply the mask to the original image to extract the region inside the contour\n",
    "# image_inside_contour = cv2.bitwise_and(opening, opening, mask=mask)\n",
    "\n",
    "# # Save or display the extracted region\n",
    "# cv2.imwrite('image_inside_contour.jpg', image_inside_contour)\n",
    "# # cv2.imshow('Image Inside Contour', image_inside_contour)\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################### Invert the Binary Image #########################################\n",
    "# # Invert the colors of each small image\n",
    "# inverted_images = [255 - image for image in small_images]\n",
    "\n",
    "# # Display or save the inverted images\n",
    "# for idx, inverted_image in enumerate(inverted_images):\n",
    "#     cv2.imwrite(f'inverted_image_{idx}.jpg', inverted_image)\n",
    "#     # Uncomment the following line to display the inverted images\n",
    "#     # cv2.imshow(f'Inverted Image {idx}', inverted_image)\n",
    "\n",
    "# # Uncomment the following line to display the inverted images\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Display or save the resized images\n",
    "for idx, small_image in enumerate(small_images):\n",
    "    cv2.imwrite(f'input_img/resized_image_{idx}.jpg', small_image)\n",
    "    # Uncomment the following line to display the resized images\n",
    "    # cv2.imshow(f'Resized Image {idx}', resized_image)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f7691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
